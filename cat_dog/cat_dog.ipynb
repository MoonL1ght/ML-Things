{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cat_dog.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"XyCnf4WrtG1r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":8}],"base_uri":"https://localhost:8080/","height":508},"outputId":"d3d51dd8-2c92-4849-e53c-7276d89d23bc","executionInfo":{"status":"ok","timestamp":1519038673583,"user_tz":-180,"elapsed":13227,"user":{"displayName":"Merrill Lynch","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114844410458529883843"}}},"cell_type":"code","source":["!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n","!pip install tqdm\n","!pip install -U -q PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package libxext6:amd64.\n","(Reading database ... 16669 files and directories currently installed.)\n","Preparing to unpack .../libxext6_2%3a1.3.3-1_amd64.deb ...\n","Unpacking libxext6:amd64 (2:1.3.3-1) ...\n","Selecting previously unselected package x11-common.\n","Preparing to unpack .../x11-common_1%3a7.7+19ubuntu3_all.deb ...\n","Unpacking x11-common (1:7.7+19ubuntu3) ...\n","Selecting previously unselected package libice6:amd64.\n","Preparing to unpack .../libice6_2%3a1.0.9-2_amd64.deb ...\n","Unpacking libice6:amd64 (2:1.0.9-2) ...\n","Selecting previously unselected package libsm6:amd64.\n","Preparing to unpack .../libsm6_2%3a1.2.2-1_amd64.deb ...\n","Unpacking libsm6:amd64 (2:1.2.2-1) ...\n","Setting up libxext6:amd64 (2:1.3.3-1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up x11-common (1:7.7+19ubuntu3) ...\n","update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libice6:amd64 (2:1.0.9-2) ...\n","Setting up libsm6:amd64 (2:1.2.2-1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Collecting tqdm\n","  Downloading tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 802kB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","Successfully installed tqdm-4.19.5\n"],"name":"stdout"}]},{"metadata":{"id":"1GJkAIfhvRym","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n","# for file1 in file_list:\n","#   print('title: %s, id: %s' % (file1['title'], file1['id']))\n","\n","#2. Get the file\n","downloaded = drive.CreateFile({'id':'1GRWv50mpTON7ZoybA7-RoxBQ4AgrjnOB'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('train.zip') \n","\n","#2. Get the file\n","downloaded = drive.CreateFile({'id':'1J_bWRKyUYmBmJAhxaV1xjDn7VTsinvLO'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('test.zip')  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0NCBXlksrlOn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"fd57cc24-c5c4-43cb-f4b8-89eeb078c40f","executionInfo":{"status":"ok","timestamp":1518687325651,"user_tz":-180,"elapsed":791,"user":{"displayName":"Merrill Lynch","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114844410458529883843"}}},"cell_type":"code","source":["!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["datalab  res.csv  test\ttest.zip  train  train.zip\r\n"],"name":"stdout"}]},{"metadata":{"id":"A8-T9v3LwTwE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import zipfile\n","zip_ref = zipfile.ZipFile('./train.zip', 'r')\n","zip_ref.extractall('./')\n","zip_ref.close()\n","zip_ref = zipfile.ZipFile('./test.zip', 'r')\n","zip_ref.extractall('./')\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7pzGXUjImqkp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":35},"outputId":"a313c112-c294-463a-91c5-afc5c5819c82","executionInfo":{"status":"ok","timestamp":1519038768446,"user_tz":-180,"elapsed":598,"user":{"displayName":"Merrill Lynch","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114844410458529883843"}}},"cell_type":"code","source":["import re\n","import os\n","TRAIN_DIR = './train/'\n","TEST_DIR = './test/'\n","ordered_files = sorted(os.listdir(TEST_DIR), key=lambda x: (int(re.sub('\\D','',x)),x))\n","test_images =  [TEST_DIR+i for i in ordered_files]\n","print(len(test_images))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["12500\n"],"name":"stdout"}]},{"metadata":{"id":"SWrDacy0tDHt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":18},{"item_id":19}],"base_uri":"https://localhost:8080/","height":989},"outputId":"b5c4ecbb-075d-416b-a070-bd70079a1b75","executionInfo":{"status":"error","timestamp":1519049990495,"user_tz":-180,"elapsed":2196688,"user":{"displayName":"Merrill Lynch","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114844410458529883843"}}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import cv2\n","from tqdm import tqdm\n","from sklearn.model_selection import KFold\n","import tensorflow as tf\n","from tensorflow.contrib.layers import dropout\n","import csv\n","import time\n","import re\n","\n","TRAIN_DIR = './train/'\n","TEST_DIR = './test/'\n","\n","IMAGE_SIZE = 200;\n","CHANNELS = 3\n","\n","valid_size = 50\n","pixel_depth = 255.0\n","\n","train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n","\n","def read_image(file_path):\n","  img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n","  if (img.shape[0] >= img.shape[1]):\n","    resizeto = (IMAGE_SIZE, int(round(IMAGE_SIZE * (float(img.shape[1]) / img.shape[0]))))\n","  else:\n","    resizeto = (int(round(IMAGE_SIZE * (float(img.shape[0])  / img.shape[1]))), IMAGE_SIZE)\n","  img = cv2.resize(img, (resizeto[1], resizeto[0]), interpolation=cv2.INTER_CUBIC)\n","#   img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_CUBIC)\n","  img = cv2.copyMakeBorder(img, 0, IMAGE_SIZE - img.shape[0], 0,\n","    IMAGE_SIZE - img.shape[1], cv2.BORDER_CONSTANT, 0)\n","  return img[:,:,::-1]\n","\n","def prep_images(images, normalize=True):\n","  count = len(images)\n","  data = np.ndarray((count, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.float32)\n","#   for i in tqdm(range(count)):\n","  for i in range(count):\n","    image = read_image(images[i])\n","    image_data = np.array(image, dtype=np.float32)\n","    if normalize:\n","      image_data[:,:,0] = image_data[:,:,0].astype(float) / pixel_depth\n","      image_data[:,:,1] = image_data[:,:,1].astype(float) / pixel_depth\n","      image_data[:,:,2] = image_data[:,:,2].astype(float) / pixel_depth\n","    data[i] = image_data\n","  return data\n","\n","def randomize_data(data):\n","  data = np.array(data)\n","  permutation = np.random.permutation(data.shape[0])\n","  shuffled_data = data[permutation]\n","  return shuffled_data\n","\n","train_images = randomize_data(train_images)\n","\n","# train_labels = np.array([1 if 'dog' in i else 0 for i in train_images[:3000]])\n","# train_normalized = prep_images(train_images[:3000])\n","\n","print(\"Train dataset shape: {}\".format(train_images.shape))\n","\n","# plt.imshow(train_normalized[0,:,:,:])\n","# plt.show()\n","\n","# train_dataset, train_labels = train_normalized, train_labels\n","\n","def create_val_set(data, labels, valid_size):\n","  data_size = data.shape[0]\n","  all_indices = np.array((range(data_size)))\n","  val_indices = np.random.choice(range(data_size), valid_size, replace=False)\n","  train_indices = np.delete(all_indices, val_indices)\n","  data_train = np.delete(data, val_indices, axis=0)\n","  label_train = np.delete(labels, val_indices, axis=0)\n","  data_val = np.delete(data, train_indices, axis=0)\n","  label_val = np.delete(labels, train_indices, axis=0)\n","  return data_train, label_train, data_val, label_val\n","\n","train_dataset, train_labels,\\\n","valid_dataset, valid_labels = create_val_set(train_images, train_images, valid_size)\n","\n","print('Train dataset shape: {}'.format(train_dataset.shape))\n","print('Train labels shape: {}'.format(train_labels.shape))\n","print('Validation dataset shape: {}'.format(valid_dataset.shape))\n","print('Validation labels shape: {}'.format(valid_labels.shape))\n","\n","learning_rate = 0.001\n","conv_keep_prob = 0.9\n","fc_keep_prob = 0.5\n","\n","num_classes= 2\n","\n","X = tf.placeholder(tf.float32,\n","  shape=(None, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n","y = tf.placeholder(tf.int32, shape=(None)) # 1 - dog, 0 - cat\n","is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n","\n","def create_conv(x, kernel_shape, stride, name):\n","  with tf.name_scope(name):\n","    conv_kernel_init = tf.truncated_normal(kernel_shape, dtype=tf.float32, stddev=0.1)\n","    conv_kernel = tf.Variable(conv_kernel_init, name='weights_'+name)\n","    conv_bias = tf.Variable(tf.constant(0.0, shape=[kernel_shape[-1]], dtype=tf.float32),\n","      trainable=True, name='biases_'+name)\n","    conv = tf.nn.conv2d(x, conv_kernel, stride, padding='SAME')\n","    out = tf.nn.relu(tf.nn.bias_add(conv, conv_bias))\n","    return out\n","\n","conv1 = create_conv(X, [3, 3, 3, 64], [1, 1, 1, 1], 'conv1')\n","conv1_1 = create_conv(conv1, [3, 3, 64, 64], [1, 1, 1, 1], 'conv1_1')\n","pool1 = tf.nn.max_pool(conv1_1,\n","  ksize=[1, 2, 2, 1],\n","  strides=[1, 2, 2, 1],\n","  padding='SAME',\n","  name='pool1')\n","# drop1 = dropout(pool1, conv_keep_prob, is_training=is_training)\n","conv2 = create_conv(pool1, [3, 3, 64, 128], [1, 1, 1, 1], 'conv2')\n","conv2_2 = create_conv(conv2, [3, 3, 128, 128], [1, 1, 1, 1], 'conv2_2')\n","pool2 = tf.nn.max_pool(conv2_2,\n","  ksize=[1, 2, 2, 1],\n","  strides=[1, 2, 2, 1],\n","  padding='SAME',\n","  name='pool2')\n","# drop2 = dropout(pool2, conv_keep_prob, is_training=is_training)\n","conv3 = create_conv(pool2, [3, 3, 128, 256], [1, 1, 1, 1], 'conv3')\n","conv3_1 = create_conv(conv3, [3, 3, 256, 256], [1, 1, 1, 1], 'conv3_1')\n","conv3_2 = create_conv(conv3_1, [3, 3, 256, 256], [1, 1, 1, 1], 'conv3_2')\n","pool3 = tf.nn.max_pool(conv3_2,\n","  ksize=[1, 2, 2, 1],\n","  strides=[1, 2, 2, 1],\n","  padding='SAME',\n","  name='pool3')\n","# drop3 = dropout(pool3, conv_keep_prob, is_training=is_training)\n","conv4 = create_conv(pool3, [3, 3, 256, 512], [1, 1, 1, 1], 'conv4')\n","conv4_1 = create_conv(conv4, [3, 3, 512, 512], [1, 1, 1, 1], 'conv4_1')\n","conv4_2 = create_conv(conv4_1, [3, 3, 512, 512], [1, 1, 1, 1], 'conv4_2')\n","pool4 = tf.nn.max_pool(conv4_2,\n","  ksize=[1, 2, 2, 1],\n","  strides=[1, 2, 2, 1],\n","  padding='SAME',\n","  name='pool4')\n","# drop4 = dropout(pool4, conv_keep_prob, is_training=is_training)\n","conv5 = create_conv(pool4, [3, 3, 512, 512], [1, 1, 1, 1], 'conv5')\n","conv5_1 = create_conv(conv5, [3, 3, 512, 512], [1, 1, 1, 1], 'conv5_1')\n","conv5_2 = create_conv(conv5_1, [3, 3, 512, 512], [1, 1, 1, 1], 'conv5_2')\n","pool5 = tf.nn.max_pool(conv5_2,\n","  ksize=[1, 2, 2, 1],\n","  strides=[1, 2, 2, 1],\n","  padding='SAME',\n","  name='pool5')\n","# drop5 = dropout(pool5, conv_keep_prob, is_training=is_training)\n","# conv6 = create_conv(drop5, [3, 3, 128, 128], [1, 1, 1, 1], 'conv6')\n","# pool6 = tf.nn.max_pool(conv6,\n","#   ksize=[1, 2, 2, 1],\n","#   strides=[1, 2, 2, 1],\n","#   padding='SAME',\n","#   name='pool6')\n","# drop6 = dropout(pool6, conv_keep_prob, is_training=is_training)\n","\n","def create_fully_connected(x, neurons, name, activation=None):\n","  with tf.name_scope(name):\n","    n_inputs = int(x.get_shape()[1])\n","    stddev = np.sqrt(2)*np.sqrt(2.0/(n_inputs+neurons))\n","    fc_init = tf.truncated_normal((n_inputs, neurons), dtype=tf.float32, stddev=stddev)\n","    fc_W =  tf.Variable(fc_init, name='fc_weights_'+name)\n","    fc_b = tf.Variable(tf.constant(0.0, shape=[neurons], dtype=tf.float32),\n","      trainable=True, name='fc_biases_'+name)\n","    z = tf.nn.bias_add(tf.matmul(x, fc_W), fc_b)\n","    if activation == 'relu':\n","      return tf.nn.relu(z)\n","    else:\n","      return z\n","\n","shape = int(np.prod(pool5.get_shape()[1:]))\n","x_flat = tf.reshape(pool5, [-1, shape])\n","\n","fc1 = create_fully_connected(x_flat, 4096, 'fc1', activation='relu')\n","fcdrop1 = dropout(fc1, fc_keep_prob, is_training=is_training)\n","fc2 = create_fully_connected(fcdrop1, 4096, 'fc2', activation='relu')\n","fcdrop2 = dropout(fc2, fc_keep_prob, is_training=is_training)\n","# fc3 = create_fully_connected(fcdrop2, 128, 'fc3', activation='relu')\n","# fcdrop3 = dropout(fc3, fc_keep_prob, is_training=is_training)\n","y_pred = create_fully_connected(fcdrop2, num_classes, 'fc_out')\n","prob_pred = tf.nn.softmax(y_pred)\n","xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_pred)\n","loss = tf.reduce_mean(xentropy)\n","optimizer = tf.train.AdamOptimizer(learning_rate)\n","training_op = optimizer.minimize(loss)\n","correct = tf.nn.in_top_k(y_pred, y, 1)\n","accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n","\n","def fetch_batch(x, y, batch_index, batch_size):\n","  start = batch_index*batch_size\n","  end = batch_index*batch_size+batch_size\n","  x_batch = x[start:end]\n","  if y is not None:\n","    y_batch = y[start:end]\n","    return x_batch, y_batch\n","  else:\n","    return x_batch\n","\n","n_epoches = 20\n","batch_size = 50\n","n_batches = int(np.ceil(train_dataset.shape[0] / batch_size))\n","print('Training settings:\\n\\tepoches: {}\\n\\tbatch size:{}\\n\\tbathes: {}'.format(n_epoches,\n","  batch_size, n_batches))\n","\n","valid_dataset = prep_images(valid_dataset)\n","valid_labels = np.array([1 if 'dog' in i else 0 for i in valid_labels])\n","init = tf.global_variables_initializer()\n","with tf.Session() as sess:\n","  sess.run(init)\n","  for epoch in range(n_epoches):\n","    for batch_index in range(n_batches):\n","      if batch_index%100==0:\n","        print(batch_index, '/', n_batches)\n","      x_batch_imgs, label_batch_imgs = fetch_batch(train_dataset, train_labels,\n","        batch_index, batch_size)\n","      x_batch = prep_images(x_batch_imgs)\n","      label_batch = np.array([1 if 'dog' in i else 0 for i in label_batch_imgs])\n","      sess.run(training_op, feed_dict={X: x_batch, y: label_batch, is_training:True})\n","    if epoch%1 == 0:\n","      loss_value = sess.run(loss, feed_dict={X: x_batch, y: label_batch, is_training:False})\n","      accuracy_value = sess.run(accuracy, feed_dict={X: x_batch, y: label_batch, is_training:False})\n","      print('Epoch: {}, batch accuracy: {:.1f}%, batch loss: {:.5f}'\\\n","        .format(epoch, (accuracy_value*100), loss_value))\n","      accuracy_valid = sess.run(accuracy, feed_dict={X: valid_dataset, y: valid_labels, is_training:False})\n","      print('Epoch: {}, validation accuracy: {:.1f}%'\\\n","        .format(epoch, (accuracy_valid*100)))\n","    \n","  print('Training has finished')\n","\n","  time.sleep(2)\n","  ordered_files = sorted(os.listdir(TEST_DIR), key=lambda x: (int(re.sub('\\D','',x)),x))\n","  test_images =  [TEST_DIR+i for i in ordered_files]\n","  test_normalized = prep_images(test_images)\n","  print(\"Test shape: {}\".format(test_normalized.shape))\n","  test_batches = int(np. ceil(test_normalized.shape[0] / batch_size))\n","  label_pred = np.empty((0,2), np.float32)\n","  for batch_index in range(test_batches):\n","    x_batch = fetch_batch(test_normalized, None,\n","      batch_index, batch_size)\n","    label_pred = np.append(label_pred, sess.run(prob_pred, feed_dict={X: x_batch, is_training:False}), axis=0)\n","  print(label_pred.shape)\n","  print(label_pred[:20])\n","  with open('./res.csv', 'w', newline='') as csvfile:\n","    csvwriter = csv.writer(csvfile, delimiter=',')\n","    csvwriter.writerow(['id', 'label'])\n","    for i, v in enumerate(label_pred):\n","      csvwriter.writerow([i+1, v[1]])"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Train dataset shape: (25000,)\n","Train dataset shape: (24950,)\n","Train labels shape: (24950,)\n","Validation dataset shape: (50,)\n","Validation labels shape: (50,)\n","Training settings:\n","\tepoches: 20\n","\tbatch size:50\n","\tbathes: 499\n","0 / 499\n","100 / 499\n","200 / 499\n","300 / 499\n","400 / 499\n","Epoch: 0, batch accuracy: 56.0%, batch loss: 0.66162\n","Epoch: 0, validation accuracy: 42.0%\n","0 / 499\n","100 / 499\n","200 / 499\n","300 / 499\n","400 / 499\n","Epoch: 1, batch accuracy: 62.0%, batch loss: 0.65659\n","Epoch: 1, validation accuracy: 34.0%\n","0 / 499\n","100 / 499\n","200 / 499\n","300 / 499\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-af8a75c524c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m       x_batch_imgs, label_batch_imgs = fetch_batch(train_dataset, train_labels,\n\u001b[1;32m    216\u001b[0m         batch_index, batch_size)\n\u001b[0;32m--> 217\u001b[0;31m       \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m       \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'dog'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_batch_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-af8a75c524c2>\u001b[0m in \u001b[0;36mprep_images\u001b[0;34m(images, normalize)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#   for i in tqdm(range(count)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-af8a75c524c2>\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mresizeto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"HBi8RFZ3KN-E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from google.colab import files\n","\n","files.download('./res.csv')"],"execution_count":0,"outputs":[]}]}